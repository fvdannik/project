Отток клиентов

Из «Бета-Банка» стали уходить клиенты. Каждый месяц. Немного, но заметно. Банковские маркетологи посчитали: сохранять текущих клиентов дешевле, чем привлекать новых.

Нужно спрогнозировать, уйдёт клиент из банка в ближайшее время или нет. Вам предоставлены исторические данные о поведении клиентов и расторжении договоров с банком. 

Постройте модель с предельно большим значением *F1*-меры. Чтобы сдать проект успешно, нужно довести метрику до 0.59. Проверьте *F1*-меру на тестовой выборке самостоятельно.

Дополнительно измеряйте *AUC-ROC*, сравнивайте её значение с *F1*-мерой.

Источник данных: [https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling](https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling)

Признаков:
- RowNumber — индекс строки в данных
- CustomerId — уникальный идентификатор клиента
- Surname — фамилия
- CreditScore — кредитный рейтинг
- Geography — страна проживания
- Gender — пол
- Age — возраст
- Tenure — сколько лет человек является клиентом банка
- Balance — баланс на счёте
- NumOfProducts — количество продуктов банка, используемых клиентом
- HasCrCard — наличие кредитной карты
- IsActiveMember — активность клиента
- EstimatedSalary — предполагаемая зарплата

Целевой признак:
- Exited — факт ухода клиента


При подготовке данных к обучению выявили:
- В столбце Tenure 909 пропусков (9% строк). Пропуски заполнены медианой в разбивке по целевому признаку;
- Избыточные параметры RowNumber, CustomerId и Surname для обучения. Вывели их в отдельную таблицу;
- Отсутсвие корреляции Пирсона выше порога 0.6. Следовательно мультиколлинеарность признаков также нет;
- Распределение кредитного рейтинга, возраста клиентов и баланса на счете похоже на нормальное. Распределение остальных числовых параметров далеки от нормального;
- Преобладающее большинство (36%) клиентов имеют нулевой баланс на счетах. Более того, 14% спящих клиентов из представленных данных с нулевыми остатками, и они не покинули банк. Об этом нужно сказать бизнесу, так как модель, используя эти данные, может ориентироваться на таких не приносящих прибыль клиентов. В рамках текущей задачи учитывать этот факт не будем;
- У большинства клиентов открыты по одному или двум продуктам;
- В данных разный баланс классов - покинувших банк клиентов сильно меньше (20%).

Категориальные признаки были закодированы методом OHE с учетом дамми-ловушки:
- Geography — страна проживания;
- Gender — пол.

Числовые признаки стандартизированы с помощью scaler:
- CreditScore - кредитный рейтинг;
- Age - возраст;
- Tenure - сколько лет человек является клиентом банка;
- Balance - баланс на счёте;
- NumOfProducts - количество продуктов банка, используемых клиентом;
- EstimatedSalary - предполагаемая зарплата.

Данные разделены на тренировочную (60%), валидационную (20%) и тестовую (20%) выборки.

- Дисбаланс классов значительный 1:5;
- Все три использовавшихся модели 'Дерево решений', 'Случайный лес' и 'Логистическая регрессия' показали результаты accuracy чуть лучше, чем у константной модели;
- Лучший результат метрик продемонстрировала модель 'Случайный лес';
- Худший результат метрик у модели 'Логистическая регрессия' - максимально подвержена дисбалансу классов в выборке.


**Результаты метрик моделей**

'Константная модель':
- Accuracy на train: 0.796
- Accuracy на val: 0.796

'Дерево решений' (с глубиной дерева: 10, splitter: random и min_samples_leaf: 2):
- Accuracy на train: 0.878
- Accuracy на val: 0.8515
- F1 на val: 0.561
- Площадь под ROC-кривой: 0.803

'Случайный лес' (с глубиной дерева: 10 и кол-вом деревьев: 16, criterion: entropy):
- Accuracy на train: 0.9
- Accuracy на val: 0.861
- F1 на val: 0.565
- Площадь под ROC-кривой: 0.829

'Логистическая регрессия':
- Accuracy на train: 0.81
- Accuracy на val: 0.81
- F1 на val: 0.312
- Площадь под ROC-кривой: 0.747

### **Выводы:**

Применили 2 метода изменения дисбаланса классов - гиперпараметр class_weight='balanced' и upsampling:
- Лучше всех показала себя модель 'Случайный лес' с использованием class_weight='balanced';
- Модель 'Дерево решений' не продемонстрировала изменения в показателях метрик;
- Модель 'Логистическая регрессия' показала значительный рост показателя метрики f1 после выравнивания баланса классов;
- После выравнивания баланса классов показатель accuracy снизился.

**Результаты метрик моделей**

1) Показатели **'Дерево решений'**

Без учета баланса классов:
- Accuracy на train: 0.878
- Accuracy на val: 0.8515
- F1 на val: 0.561
- Площадь под ROC-кривой: 0.803

C гиперпараметром class_weight='balanced':
- Accuracy на train: 0.824
- Accuracy на val: 0.771
- F1 на val: 0.547
- Площадь под ROC-кривой: 0.788

С использованием upsampling:
- Accuracy на train: 0.824
- Accuracy на val: 0.774
- F1 на val: 0.534
- Площадь под ROC-кривой: 0.769



2) Показатели **'Случайный лес'** 

Без учета баланса классов:
- Accuracy на train: 0.9
- Accuracy на val: 0.861
- F1 на val: 0.565
- Площадь под ROC-кривой: 0.829

С гиперпараметром class_weight='balanced':
- Accuracy на train: 0.907
- Accuracy на val: 0.827
- F1 на val: 0.597
- Площадь под ROC-кривой: 0.836

С использованием upsampling:
- Accuracy на train: 0.884
- Accuracy на val: 0.812
- F1 на val: 0.591
- Площадь под ROC-кривой: 0.836



3) Показатели **'Логистической регрессии'**

Без учета баланса классов:
- Accuracy на train: 0.81
- Accuracy на val: 0.81
- F1 на val: 0.312
- Площадь под ROC-кривой: 0.747

С гиперпараметром class_weight='balanced':
- Accuracy на train: 0.711
- Accuracy на val: 0.706
- F1 на val: 0.478
- Площадь под ROC-кривой: 0.752

С использованием upsampling:
- Accuracy на train: 0.71
- Accuracy на val: 0.703
- F1 на val: 0.477
- Площадь под ROC-кривой: 0.752

## **Общий вывод:**

Проведено исследование исторических данных о поведении клиентов и расторжении договоров с банком.

По результатам исследования ставилась цель построить модель прогнозирования, которая будет определять уйдёт клиент из банка в ближайшее время или нет, с предельно большим значением *F1*-меры (более 0.59).

**Результаты ознакомления с данными:**

- 9% строк пропусков столбца Tenure (сколько лет человек является клиентом банка) заполнены медианой в разбивке по целевому признаку;
- Избыточные для обучения параметры RowNumber (индекс строки в данных), CustomerId (уникальный идентификатор клиента) и Surname (фамилия) выведены в отдельную таблицу;
- Отсутсвует мультиколлинеарность признаков;
- Распределение кредитного рейтинга, возраста клиентов и баланса на счете похоже на нормальное. Распределение остальных числовых параметров далеки от нормального;
- Преобладающее большинство (36%) клиентов имеют нулевой баланс на счетах. Более того, 14% спящих клиентов из представленных данных с нулевыми остатками, и они не покинули банк. Об этом нужно сказать бизнесу, так как модель, используя эти данные, может ориентироваться на таких не приносящих прибыль клиентов. В рамках текущей задачи этот факт не учитывается;
- У большинства клиентов открыты по одному или двум продуктам;
- В данных разный баланс классов (1:5) - покинувших банк клиентов сильно меньше (20%).

**Исследование разных моделей и борьба с дисбалансом классов:**

Проведена работа по подбору гиперпараметров 3-х разных моделей ('Дерево решений', 'Случайный лес' и 'Логистическая регрессия') **без учета дисбаланса классов**:

- В результате использования наиболее подходящих гиперпараметров все три модели показали результат метрики accuracy чуть лучше, чем у константной модели.
- Лучший результат метрик продемонстрировала модель 'Случайный лес';
- Худший результат метрик у модели 'Логистическая регрессия' - максимально подвержена дисбалансу классов в выборке.

Протестированы 2 метода **балансировки классов** - гиперпараметр class_weight='balanced' и upsampling:
- Лучше всех показала себя модель 'Случайный лес' с использованием class_weight='balanced';
- Модель 'Дерево решений' не продемонстрировала изменения в показателях метрик после балансировки;
- Модель 'Логистическая регрессия' показала значительный рост показателя метрики f1 после выравнивания баланса классов;
- После выравнивания баланса классов показатель accuracy снизился.

По результатам исследования выявлена лучшая модель 'Случайный лес' с параметрами:
- глубина дерева 10;
- количество деревьев равной 16;
- с использованием критерия 'entropy';
- модель обучалась на выборке, сбалансированной методом class_weight='balanced'.

**Рекомендованная к использованию модель 'Случайный лес'** показала следующие результаты на тестовой выборке:
- Accuracy на train: 0.907
- Accuracy на test: 0.8455
- F1 на test: 0.63 (> 0.59)
- Площадь под ROC-кривой на test: 0.866

